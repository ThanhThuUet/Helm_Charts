apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap-aggregator
data:
  fluentd.conf: |

    # Ignore fluentd own events
    <label @FLUENT_LOG>
      <match fluent.*>
        @type null
      </match>
    </label>
    # <match fluent.**>
    #   @type null
    # </match>

    # TCP input to receive logs from the forwarders
    <source>
      @type forward
      bind 0.0.0.0
      port 24224
    </source>

    # HTTP input for the liveness and readiness probes
    <source>
      @type http
      bind 0.0.0.0
      port 9880
    </source>

    # Throw the healthcheck to the standard output instead of forwarding it
    <match fluentd.healthcheck>
      @type stdout
    </match>

    # Send the logs to the standard output
    <match **>
      @type elasticsearch_dynamic
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
      password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
      scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
      ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'true'}"
      logstash_format true
      logstash_dateformat %Y.%m.%d
      logstash_prefix "#{ENV['LOGSTASH_PREFIX']}"
      suppress_type_name "#{ENV['FLUENT_ELASTICSEARCH_SUPPRESS_TYPE_NAME'] || 'true'}"
      reload_connections false
      reconnect_on_error true
      reload_on_failure true
      # Out of memory
      request_timeout 900s
      <buffer>
        @type file
        path /opt/bitnami/fluentd/logs/buffers/logs.buffer
        flush_mode interval
        retry_type exponential_backoff
        flush_thread_count 4
        flush_interval 1s
        retry_forever true
        retry_max_interval 30
        chunk_limit_size 2M
        queue_limit_length 64
        # overflow_action drop_oldest_chunk
        overflow_action block
      </buffer>
    </match>
